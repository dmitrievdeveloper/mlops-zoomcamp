{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "from evidently import ColumnMapping\n",
        "from evidently.report import Report\n",
        "from evidently.metrics import ColumnDriftMetric, DatasetDriftMetric, DatasetMissingValuesMetric, ColumnQuantileMetric, DatasetSummaryMetric\n",
        "\n",
        "from joblib import load, dump\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
        "\n",
        "# Create directories if they don't exist\n",
        "Path(\"data\").mkdir(exist_ok=True)\n",
        "Path(\"models\").mkdir(exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def download_data():\n",
        "    \"\"\"Download March 2024 Green Taxi data\"\"\"\n",
        "    \n",
        "    file = 'green_tripdata_2024-03.parquet'\n",
        "    url = f\"https://d37ci6vzurychx.cloudfront.net/trip-data/{file}\"\n",
        "    save_path = f\"data/{file}\"\n",
        "    \n",
        "    if not Path(save_path).exists():\n",
        "        print(f\"Downloading {file}...\")\n",
        "        resp = requests.get(url, stream=True)\n",
        "        with open(save_path, \"wb\") as handle:\n",
        "            for data in tqdm(resp.iter_content(), \n",
        "                            desc=f\"{file}\",\n",
        "                            postfix=f\"save to {save_path}\",\n",
        "                            total=int(resp.headers[\"Content-Length\"])):\n",
        "                handle.write(data)\n",
        "    else:\n",
        "        print(f\"{file} already exists, skipping download\")\n",
        "    \n",
        "    return save_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_data(data_path):\n",
        "    \"\"\"Load and prepare the taxi data\"\"\"\n",
        "    print(\"=== Loading and preparing data ===\")\n",
        "    \n",
        "    # Load data\n",
        "    mar_data = pd.read_parquet(data_path)\n",
        "    print(f\" Data shape is {mar_data.shape} - {mar_data.shape[0]} rows\")\n",
        "    \n",
        "    # Create target variable\n",
        "    mar_data[\"duration_min\"] = mar_data.lpep_dropoff_datetime - mar_data.lpep_pickup_datetime\n",
        "    mar_data.duration_min = mar_data.duration_min.apply(lambda td: float(td.total_seconds())/60)\n",
        "    \n",
        "    # Filter outliers\n",
        "    mar_data = mar_data[(mar_data.duration_min >= 0) & (mar_data.duration_min <= 60)]\n",
        "    mar_data = mar_data[(mar_data.passenger_count > 0) & (mar_data.passenger_count <= 8)]\n",
        "    \n",
        "    print(f\"After filtering: {mar_data.shape}\")\n",
        "    \n",
        "    return mar_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(mar_data):\n",
        "    \"\"\"Train the baseline linear regression model\"\"\"\n",
        "    print(\"=== Training baseline model ===\")\n",
        "    \n",
        "    # Define features\n",
        "    target = \"duration_min\"\n",
        "    num_features = [\"passenger_count\", \"trip_distance\", \"fare_amount\", \"total_amount\"]\n",
        "    cat_features = [\"PULocationID\", \"DOLocationID\"]\n",
        "    \n",
        "    # Split data\n",
        "    train_data = mar_data[:30000].copy()\n",
        "    val_data = mar_data[30000:].copy()\n",
        "    \n",
        "    # Train model\n",
        "    model = LinearRegression()\n",
        "    model.fit(train_data[num_features + cat_features], train_data[target])\n",
        "    \n",
        "    # Make predictions\n",
        "    train_preds = model.predict(train_data[num_features + cat_features])\n",
        "    val_preds = model.predict(val_data[num_features + cat_features])\n",
        "    \n",
        "    train_data['prediction'] = train_preds\n",
        "    val_data['prediction'] = val_preds\n",
        "    \n",
        "    # Print metrics\n",
        "    train_mae = mean_absolute_error(train_data.duration_min, train_data.prediction)\n",
        "    val_mae = mean_absolute_error(val_data.duration_min, val_data.prediction)\n",
        "    print(f\"Train MAE: {train_mae:.4f}\")\n",
        "    print(f\"Validation MAE: {val_mae:.4f}\")\n",
        "    \n",
        "    # Save model and reference data\n",
        "    with open('models/lin_reg.bin', 'wb') as f_out:\n",
        "        dump(model, f_out)\n",
        "    \n",
        "    val_data.to_parquet('data/reference.parquet')\n",
        "    \n",
        "    return train_data, val_data, num_features, cat_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def setup_monitoring(train_data, val_data, num_features, cat_features):\n",
        "    \"\"\"Set up monitoring with Evidently metrics\"\"\"\n",
        "    \n",
        "    # Column mapping - only include numeric and categorical features, exclude datetime\n",
        "    column_mapping = ColumnMapping(\n",
        "        target=None,\n",
        "        prediction='prediction',\n",
        "        numerical_features=num_features,\n",
        "        categorical_features=cat_features\n",
        "    )\n",
        "    \n",
        "    report = Report(metrics=[\n",
        "        ColumnDriftMetric(column_name='prediction'),\n",
        "        DatasetDriftMetric(),\n",
        "        DatasetMissingValuesMetric(),\n",
        "        ColumnQuantileMetric(column_name='fare_amount', quantile=0.5),  \n",
        "        DatasetSummaryMetric() \n",
        "    ])\n",
        "    \n",
        "    # Run initial report\n",
        "    report.run(reference_data=train_data, current_data=val_data, column_mapping=column_mapping)\n",
        "    \n",
        "    \n",
        "    return column_mapping\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def daily_monitoring(mar_data, column_mapping):\n",
        "    \n",
        "    # Add date column\n",
        "    mar_data['date'] = mar_data.lpep_pickup_datetime.dt.date\n",
        "    unique_dates = sorted(mar_data['date'].unique())\n",
        "    \n",
        "    quantile_values = []\n",
        "    daily_results = []\n",
        "    \n",
        "    print(f\"Processing {len(unique_dates)} days...\")\n",
        "    \n",
        "    for i, date in enumerate(unique_dates):\n",
        "        # Filter data for this specific date\n",
        "        daily_data = mar_data[mar_data['date'] == date].copy()\n",
        "        \n",
        "        if len(daily_data) > 10:  # Only process if there's sufficient data\n",
        "            try:\n",
        "                # Create daily report with quantile metric\n",
        "                daily_report = Report(\n",
        "                    metrics=[ColumnQuantileMetric(column_name='fare_amount', quantile=0.5)],\n",
        "                    timestamp=datetime.datetime.combine(date, datetime.time())\n",
        "                )\n",
        "                \n",
        "                # Run the report\n",
        "                daily_report.run(reference_data=None, current_data=daily_data, column_mapping=column_mapping)\n",
        "                \n",
        "                # Extract quantile value\n",
        "                result = daily_report.as_dict()\n",
        "                quantile_value = result['metrics'][0]['result']['current']['value']\n",
        "                quantile_values.append(quantile_value)\n",
        "                daily_results.append((date, quantile_value, len(daily_data)))\n",
        "                \n",
        "                print(f\"Date: {date}, Rows: {len(daily_data):4d}, Quantile 0.5: {quantile_value:.2f}\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {date}: {e}\")\n",
        "                continue\n",
        "    \n",
        "    if not quantile_values:\n",
        "        print(\"No quantile values calculated!\")\n",
        "        return None\n",
        "    \n",
        "    # Find maximum quantile value\n",
        "    max_quantile = max(quantile_values)\n",
        "    max_date = daily_results[quantile_values.index(max_quantile)][0]\n",
        "    \n",
        "    print(f\"\\nMaximum quantile 0.5 value for fare_amount in March 2024: {max_quantile:.1f}\")\n",
        "    print(f\"This maximum occurred on: {max_date}\")\n",
        "    \n",
        "    # Check against multiple choice options\n",
        "    options = [10, 12.5, 14.2, 14.8]\n",
        "    closest_option = min(options, key=lambda x: abs(x - max_quantile))\n",
        "    \n",
        "    return max_quantile\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "green_tripdata_2024-03.parquet already exists, skipping download\n",
            "=== Loading and preparing data ===\n",
            " Data shape is (57457, 20) - 57457 rows\n",
            "After filtering: (54135, 21)\n"
          ]
        }
      ],
      "source": [
        "# Download and prepare data\n",
        "data_path = download_data()\n",
        "mar_data = prepare_data(data_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Training baseline model ===\n",
            "Train MAE: 3.7725\n",
            "Validation MAE: 3.7168\n"
          ]
        }
      ],
      "source": [
        "# Train baseline model\n",
        "train_data, val_data, num_features, cat_features = train_model(mar_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Q2: Setup monitoring with expanded metrics\n",
        "column_mapping = setup_monitoring(train_data, val_data, num_features, cat_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing 37 days...\n",
            "Date: 2024-03-01, Rows: 1994, Quantile 0.5: 13.50\n",
            "Date: 2024-03-02, Rows: 1509, Quantile 0.5: 12.80\n",
            "Date: 2024-03-03, Rows: 1385, Quantile 0.5: 14.20\n",
            "Date: 2024-03-04, Rows: 1820, Quantile 0.5: 12.80\n",
            "Date: 2024-03-05, Rows: 1867, Quantile 0.5: 12.80\n",
            "Date: 2024-03-06, Rows: 2174, Quantile 0.5: 12.80\n",
            "Date: 2024-03-07, Rows: 2012, Quantile 0.5: 13.50\n",
            "Date: 2024-03-08, Rows: 1964, Quantile 0.5: 12.80\n",
            "Date: 2024-03-09, Rows: 1655, Quantile 0.5: 13.50\n",
            "Date: 2024-03-10, Rows: 1337, Quantile 0.5: 14.20\n",
            "Date: 2024-03-11, Rows: 1742, Quantile 0.5: 12.80\n",
            "Date: 2024-03-12, Rows: 1792, Quantile 0.5: 12.80\n",
            "Date: 2024-03-13, Rows: 1961, Quantile 0.5: 13.50\n",
            "Date: 2024-03-14, Rows: 1974, Quantile 0.5: 14.20\n",
            "Date: 2024-03-15, Rows: 1906, Quantile 0.5: 13.50\n",
            "Date: 2024-03-16, Rows: 1580, Quantile 0.5: 13.50\n",
            "Date: 2024-03-17, Rows: 1349, Quantile 0.5: 13.50\n",
            "Date: 2024-03-18, Rows: 1775, Quantile 0.5: 12.80\n",
            "Date: 2024-03-19, Rows: 1859, Quantile 0.5: 13.50\n",
            "Date: 2024-03-20, Rows: 1938, Quantile 0.5: 12.80\n",
            "Date: 2024-03-21, Rows: 2010, Quantile 0.5: 13.50\n",
            "Date: 2024-03-22, Rows: 1830, Quantile 0.5: 12.80\n",
            "Date: 2024-03-23, Rows: 1289, Quantile 0.5: 12.80\n",
            "Date: 2024-03-24, Rows: 1296, Quantile 0.5: 14.02\n",
            "Date: 2024-03-25, Rows: 1702, Quantile 0.5: 13.50\n",
            "Date: 2024-03-26, Rows: 1833, Quantile 0.5: 13.50\n",
            "Date: 2024-03-27, Rows: 1938, Quantile 0.5: 12.80\n",
            "Date: 2024-03-28, Rows: 2018, Quantile 0.5: 13.25\n",
            "Date: 2024-03-29, Rows: 1734, Quantile 0.5: 12.80\n",
            "Date: 2024-03-30, Rows: 1483, Quantile 0.5: 14.00\n",
            "Date: 2024-03-31, Rows: 1399, Quantile 0.5: 13.50\n",
            "\n",
            "Maximum quantile 0.5 value for fare_amount in March 2024: 14.2\n",
            "This maximum occurred on: 2024-03-03\n"
          ]
        }
      ],
      "source": [
        "# Q3: Daily monitoring to find maximum quantile value\n",
        "max_quantile = daily_monitoring(mar_data, column_mapping)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "exp-tracking-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
